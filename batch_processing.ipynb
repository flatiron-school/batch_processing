{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1982b62",
   "metadata": {},
   "source": [
    "# Batch Processing with `joblib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20e419fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil, sqrt\n",
    "import random\n",
    "import datetime\n",
    "from joblib import Parallel, delayed, Memory\n",
    "from typing import Callable, Dict, List, Union\n",
    "from multiprocessing import Queue, Manager\n",
    "from threading import Thread\n",
    "\n",
    "import tqdm as tqdm_\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm_batch import batch_process\n",
    "\n",
    "sns.set_context('poster')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba531e08",
   "metadata": {},
   "source": [
    "![img](https://res.cloudinary.com/hevo/images/f_auto,q_auto/v1649315584/hevo-learn/Batch-Processing-Batch-Processing-vs-Stream-Processing/Batch-Processing-Batch-Processing-vs-Stream-Processing.png?_i=AA)\n",
    "\n",
    "(Source: https://hevodata.com/learn/batch-processing/.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37921d98",
   "metadata": {},
   "source": [
    "## Definition\n",
    "\n",
    "Jobs that can run without end user interaction, or can be scheduled to run as resources permit, are called batch jobs. Batch processing is for those frequently used programs that can be executed with minimal human interaction.\n",
    "\n",
    "A program that reads a large file and generates a report, for example, is considered to be a batch job.\n",
    "\n",
    "The term batch job originated in the days when punched cards contained the directions for a computer to follow when running one or more programs. Multiple card decks representing multiple jobs would often be stacked on top of one another in the hopper of a card reader, and be run in batches.\n",
    "\n",
    "(Source: https://www.ibm.com/docs/en/zos-basic-skills?topic=jobs-what-is-batch-processing.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65631636",
   "metadata": {},
   "source": [
    "Batch processing is to be contrasted with serial or *stream* processing. Stream processing is critical when you need real-time updating of data reports or analyses. But if you are processing large chunks of data, it can be better to process it in batches.\n",
    "\n",
    "Batch processing works in an **automated** way based on a **scheduler**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c858cb",
   "metadata": {},
   "source": [
    "More useful introductory discussion [here](https://www.talend.com/resources/batch-processing/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48993a05",
   "metadata": {},
   "source": [
    "## Batch size\n",
    "The batch size refers to the number of work units to be processed within one batch operation. Some examples are:\n",
    "\n",
    "- The number of lines from a file to load into a database before committing the transaction.\n",
    "- The number of messages to dequeue from a queue.\n",
    "- The number of requests to send within one payload.\n",
    "\n",
    "## Common batch processing usage\n",
    "\n",
    "- Efficient bulk database updates and automated transaction processing, as contrasted to interactive online transaction processing (OLTP) applications.\n",
    "- The extract, transform, load (ETL) step in populating data warehouses is inherently a batch process in most implementations.\n",
    "- Performing bulk operations on digital images such as resizing, conversion, watermarking, or otherwise editing a group of image files.\n",
    "- Converting computer files from one format to another. For example, a batch job may convert proprietary and legacy files to common standard formats for end-user queries and display.\n",
    "\n",
    "(Source: https://en.wikipedia.org/wiki/Batch_processing.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6e6cc9",
   "metadata": {},
   "source": [
    "## `joblib`\n",
    "\n",
    "### Advantages\n",
    "\n",
    "- Disk Caching of Functions & Lazy Re-Evaluation\n",
    "\n",
    "Separate flow-execution logic from algorithmic logic and **memoize** to speed up computations. That is, cache the results of expensive function calls for later use.\n",
    "\n",
    "- Parallel Computing\n",
    "\n",
    "Simple and easy to debug.\n",
    "\n",
    "- Fast Storage / Compression\n",
    "\n",
    "Better than `pickle` for large objects.\n",
    "\n",
    "(Source: https://hevodata.com/learn/python-batch-processing/.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab68e849",
   "metadata": {},
   "source": [
    "### Sample Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db73a8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling square...\n",
      "square(array([[0., 0., 1.],\n",
      "       [1., 1., 1.],\n",
      "       [4., 2., 1.]]))\n",
      "___________________________________________________________square - 0.0s, 0.0min\n"
     ]
    }
   ],
   "source": [
    "cachedir = '/Library/Caches'\n",
    "mem = Memory(cachedir)\n",
    "\n",
    "a = np.vander(np.arange(3)).astype(float)\n",
    "square = mem.cache(np.square)\n",
    "b = square(a)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1895b382",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = square(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9162d75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Parallel(n_jobs=1)(delayed(sqrt)(i**2) for i in range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a732e747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.33 ms, sys: 5.89 ms, total: 9.22 ms\n",
      "Wall time: 11.5 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "Parallel(n_jobs=2, prefer='threads')(delayed(sqrt)(i**2) for i in range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7962b2",
   "metadata": {},
   "source": [
    "### `joblib` Example\n",
    "\n",
    "(Source: https://towardsdatascience.com/using-joblib-to-speed-up-your-python-pipelines-dd97440c653d.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ceed578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The function took 20.11 s to compute.\n",
      "[1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121, 144, 169, 196, 225, 256, 289, 324, 361, 400]\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "\n",
    "# Getting the square of the number:\n",
    "def square_number(no):\n",
    "    return (no*no)\n",
    "\n",
    "# Function to compute square of a range of a number:\n",
    "def get_square_range(start_no, end_no):\n",
    "    for i in np.arange(start_no, end_no):\n",
    "        time.sleep(1)\n",
    "        result.append(square_number(i))\n",
    "    return result\n",
    "\n",
    "start = time.time()\n",
    "# Getting square of 1 to 20:\n",
    "final_result = get_square_range(1, 21)\n",
    "end = time.time()\n",
    "\n",
    "# Total time to compute\n",
    "print('\\nThe function took {:.2f} s to compute.'.format(end - start))\n",
    "print(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c6abde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The function took 20.11 s to compute.\n",
      "[1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121, 144, 169, 196, 225, 256, 289, 324, 361, 400]\n"
     ]
    }
   ],
   "source": [
    "# Define a location to store cache\n",
    "location = '/Library/Caches'\n",
    "memory = Memory(location, verbose=0)\n",
    "\n",
    "result = []\n",
    "\n",
    "# Function to compute square of a range of a number:\n",
    "def get_square_range_cached(start_no, end_no):\n",
    "    for i in np.arange(start_no, end_no):\n",
    "        time.sleep(1)\n",
    "        result.append(square_number(i))\n",
    "    return result\n",
    "\n",
    "get_square_range_cached = memory.cache(get_square_range_cached)\n",
    "\n",
    "start = time.time()\n",
    "# Getting square of 1 to 20:\n",
    "final_result = get_square_range_cached(1, 21)\n",
    "end = time.time()\n",
    "\n",
    "# Total time to compute\n",
    "print('\\nThe function took {:.2f} s to compute.'.format(end - start))\n",
    "print(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5eb35c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The function took 0.01 s to compute.\n",
      "[1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121, 144, 169, 196, 225, 256, 289, 324, 361, 400]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# Getting square of 1 to 20:\n",
    "final_result = get_square_range_cached(1, 21)\n",
    "end = time.time()\n",
    "\n",
    "print('\\nThe function took {:.2f} s to compute.'.format(end - start))\n",
    "print(final_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fd9bd4",
   "metadata": {},
   "source": [
    "#### Parallelizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42ad501f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.49671415, -0.1382643 ,  0.64768854,  1.52302986],\n",
       "       [-0.23415337, -0.23413696,  1.57921282,  0.76743473],\n",
       "       [-0.46947439,  0.54256004, -0.46341769, -0.46572975],\n",
       "       [ 0.24196227, -1.91328024, -1.72491783, -0.56228753],\n",
       "       [-1.01283112,  0.31424733, -0.90802408, -1.4123037 ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.RandomState(42)\n",
    "data = rng.randn(int(1e4), 4)\n",
    "data[:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d642ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sequential processing\n",
      "Elapsed time for the entire processing: 8.02 s\n"
     ]
    }
   ],
   "source": [
    "def costly_compute(data, column):\n",
    "    \"\"\"Emulate a costly function by sleeping and returning a column.\"\"\"\n",
    "    time.sleep(2)\n",
    "    return data[column]\n",
    "\n",
    "def data_processing_mean(data, column):\n",
    "    \"\"\"Compute the mean of a column.\"\"\"\n",
    "    return costly_compute(data, column).mean()\n",
    "\n",
    "start = time.time()\n",
    "results = [data_processing_mean(data, col) for col in range(data.shape[1])]\n",
    "stop = time.time()\n",
    "\n",
    "print('\\nSequential processing')\n",
    "print('Elapsed time for the entire processing: {:.2f} s'\n",
    "      .format(stop - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "444c316b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for the entire processing: 5.04 s\n"
     ]
    }
   ],
   "source": [
    "location = '/Library/Caches'\n",
    "memory = Memory(location, verbose=0)\n",
    "costly_compute_cached = memory.cache(costly_compute)\n",
    "\n",
    "def data_processing_mean_using_cache(data, column):\n",
    "    \"\"\"Compute the mean of a column.\"\"\"\n",
    "    return costly_compute_cached(data, column).mean()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Here is where we adjust the number of workers\n",
    "results = Parallel(n_jobs=2)(\n",
    "    delayed(data_processing_mean_using_cache)(data, col)\n",
    "    for col in range(data.shape[1]))\n",
    "stop = time.time()\n",
    "\n",
    "print('Elapsed time for the entire processing: {:.2f} s'\n",
    "      .format(stop - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0e7fd2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for the entire processing: 1.21 s\n"
     ]
    }
   ],
   "source": [
    "location = '/Library/Caches'\n",
    "memory = Memory(location, verbose=0)\n",
    "costly_compute_cached = memory.cache(costly_compute)\n",
    "\n",
    "def data_processing_mean_using_cache(data, column):\n",
    "    \"\"\"Compute the mean of a column.\"\"\"\n",
    "    return costly_compute_cached(data, column).mean()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Let's try 8 workers!\n",
    "results = Parallel(n_jobs=8)(\n",
    "    delayed(data_processing_mean_using_cache)(data, col)\n",
    "    for col in range(data.shape[1]))\n",
    "stop = time.time()\n",
    "\n",
    "print('Elapsed time for the entire processing: {:.2f} s'\n",
    "      .format(stop - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a033fd3a",
   "metadata": {},
   "source": [
    "## `tqdm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec136361",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|███▊                                                   | 686330/10000000 [00:00<00:02, 3499486.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|███████▊                                              | 1452893/10000000 [00:00<00:02, 3725625.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500000500000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██████████████▏                                       | 2635172/10000000 [00:00<00:01, 3885705.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000001000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|██████████████████▌                                   | 3443847/10000000 [00:00<00:01, 3964059.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500001500000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|█████████████████████████                             | 4631914/10000000 [00:01<00:01, 3913970.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000002000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████████████████████████████▎                        | 5425966/10000000 [00:01<00:01, 3925653.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500002500000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|███████████████████████████████████▊                  | 6624304/10000000 [00:01<00:00, 3944554.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000003000000\n",
      "24500003500000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|██████████████████████████████████████████████▍       | 8610858/10000000 [00:02<00:00, 3899253.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000004000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|██████████████████████████████████████████████████▋   | 9397924/10000000 [00:02<00:00, 3894928.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40500004500000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 10000000/10000000 [00:02<00:00, 3872570.82it/s]\n"
     ]
    }
   ],
   "source": [
    "num = 0\n",
    "for j in tqdm_.tqdm(range(10000000)):\n",
    "    num += j\n",
    "    if not j % 1000000:\n",
    "        print(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bae9d4e",
   "metadata": {},
   "source": [
    "## Contrasting Serial and Batch Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ead8352",
   "metadata": {},
   "source": [
    "The function below is based on the following mathematical theorem:\n",
    "\n",
    "$\\large\\frac{\\pi}{4} = 1 - \\frac{1}{3} + \\frac{1}{5} - \\frac{1}{7} + \\frac{1}{9} - ... = lim_{n\\rightarrow\\infty}\\sum^n_{j=0}\\frac{(-1)^j}{2j+1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5376bafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_process_function(row, order, payload):\n",
    "    \"\"\"\n",
    "    Simulate process function\n",
    "    \n",
    "    Row and payload are ignored.\n",
    "    \n",
    "    Approximate pi\n",
    "    \"\"\"\n",
    "    k, pi = 1, 0\n",
    "    for i in range(10**order):\n",
    "        if i % 2 == 0: # even\n",
    "            pi += 4 / k\n",
    "        else:  # odd \n",
    "            pi -= 4 / k \n",
    "        k += 2\n",
    "    return pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4a49ee5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "order=6\n",
    "N = 1_000\n",
    "items = range(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de3adcf",
   "metadata": {},
   "source": [
    "### Serial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8660df70",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [batch_process_function(row, order, None) for row in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6569e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1415916535897743"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd069b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 57s, sys: 558 ms, total: 1min 57s\n",
      "Wall time: 1min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Serial run\n",
    "result = [batch_process_function(row, order, None) for row in items]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71629df",
   "metadata": {},
   "source": [
    "### Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe0475f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 1000/1000 [00:23<00:00, 42.85it/s]\n"
     ]
    }
   ],
   "source": [
    "result = joblib.Parallel(n_jobs=8)(\n",
    "    delayed(batch_process_function)\n",
    "    (row, order, None)\n",
    "    for row in tqdm_.tqdm(items)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05f1d1f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1415916535897743"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6fd11c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 1000/1000 [00:19<00:00, 50.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 648 ms, sys: 110 ms, total: 758 ms\n",
      "Wall time: 20.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Parallel using joblib and a progress bar using tqdm\n",
    "result = Parallel(n_jobs=8)(\n",
    "    delayed(batch_process_function)\n",
    "    (row, order, None) \n",
    "    for row in tqdm_.tqdm(items)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7852f56b",
   "metadata": {},
   "source": [
    "## Things to Be Aware of"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa81f66",
   "metadata": {},
   "source": [
    "- Batch Triggers\n",
    "- Scheduling\n",
    "- Exception Alerts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7b7119",
   "metadata": {},
   "source": [
    "## Serialize per Batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72610084",
   "metadata": {},
   "source": [
    "(Source: https://towardsdatascience.com/parallel-batch-processing-in-python-8dcce607d226)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8d628ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ec81bd3e61f401eab57cdb279facc24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Random payload to simulate a model\n",
    "matrix = np.random.normal(size=(500, 500, 100))\n",
    "\n",
    "# Use default joblib\n",
    "result = Parallel(n_jobs=8)(\n",
    "    delayed(batch_process_function)\n",
    "    (row, order, matrix) \n",
    "    for row in tqdm(items)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9ffbea68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d690009405743d283af1c20bc34bd71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_workers = 8\n",
    "\n",
    "# Create a batch function\n",
    "def proc_batch(batch, order, matrix):\n",
    "    return [\n",
    "        batch_process_function(row, order, matrix)\n",
    "        for row in batch\n",
    "    ]\n",
    "\n",
    "# Divide data in batches\n",
    "batch_size = np.ceil(len(items) / n_workers)\n",
    "batches = [\n",
    "    items[ix:ix+int(batch_size)] for ix in range(0, len(items), int(batch_size))\n",
    "]\n",
    "\n",
    "# divide the work\n",
    "result = Parallel(n_jobs=n_workers)(\n",
    "    delayed(proc_batch)\n",
    "    (batch, order, matrix) \n",
    "    for batch in tqdm(batches)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7682825e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress_bar(\n",
    "    totals: Union[int, List[int]],\n",
    "    queue : Queue,\n",
    ") -> None:\n",
    "    if isinstance(totals, list):\n",
    "        splitted = True\n",
    "        pbars = [\n",
    "            tqdm(\n",
    "                desc=f'Worker {pid + 1}',\n",
    "                total=total,\n",
    "                position=pid,\n",
    "            )\n",
    "            for pid, total in enumerate(totals)\n",
    "        ]\n",
    "    else:\n",
    "        splitted = False\n",
    "        pbars = [\n",
    "            tqdm(total=totals)\n",
    "        ]\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            message = queue.get()\n",
    "            if message.startswith('update'):\n",
    "                if splitted:\n",
    "                    pid = int(message[6:])\n",
    "                    pbars[pid].update(1)\n",
    "                else:\n",
    "                    pbars[0].update(1)\n",
    "            elif message == 'done':\n",
    "                break\n",
    "        except:\n",
    "            pass\n",
    "    for pbar in pbars:\n",
    "        pbar.close()\n",
    "\n",
    "        \n",
    "def task_wrapper(pid, function, batch, queue, *args, **kwargs):\n",
    "    result = []\n",
    "    for example in batch:\n",
    "        result.append(function(example, *args, **kwargs))\n",
    "        queue.put(f'update{pid}')\n",
    "    return result\n",
    "\n",
    "        \n",
    "def batch_process(\n",
    "    items: list,\n",
    "    function: Callable,\n",
    "    n_workers: int=8,\n",
    "    sep_progress: bool=False,\n",
    "    *args,\n",
    "    **kwargs,\n",
    "    ) -> List[Dict[str, Union[str, List[str]]]]:\n",
    "    # Divide data in batches\n",
    "    batch_size = ceil(len(items) / n_workers)\n",
    "    batches = [\n",
    "        items[ix:ix+batch_size]\n",
    "        for ix in range(0, len(items), batch_size)\n",
    "    ]\n",
    "\n",
    "    # Check single or multiple progress bars\n",
    "    if sep_progress:\n",
    "        totals = [len(batch) for batch in batches]\n",
    "    else:\n",
    "        totals = len(items)\n",
    "\n",
    "    # Start progress bar in separate thread\n",
    "    manager = Manager()\n",
    "    queue = manager.Queue()\n",
    "    progproc = Thread(target=progress_bar, args=(totals, queue))\n",
    "    progproc.start()\n",
    "\n",
    "    # Parallel process the batches\n",
    "    result = Parallel(n_jobs=n_workers)(\n",
    "        delayed(task_wrapper)\n",
    "        (pid, function, batch, queue, *args, **kwargs)\n",
    "        for pid, batch in enumerate(batches)\n",
    "    )\n",
    "\n",
    "    # Stop the progress bar thread\n",
    "    queue.put('done')\n",
    "    progproc.join()\n",
    "\n",
    "    # Flatten result\n",
    "    flattened = [item for sublist in result for item in sublist]\n",
    "\n",
    "    return flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a971edf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c3c28f1126b4b33804ee9a9a3c0a514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Worker 1:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeb3ca538f9a4ded88ac70c3fb32388e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Worker 2:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7feea53bfb8048c8a52fcfd6c09b8aa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Worker 3:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5efa11099894aec82be246c606f7233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Worker 4:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e04012ee74e4469ba87a095e56cf699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Worker 5:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7cdd2226b64432dbe85b00184a8bf37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Worker 6:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3ffd910afa34f4994f09b522a5c3f04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Worker 7:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4269ca7701ed4110a4ba83c0e03d853f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Worker 8:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = batch_process(items,\n",
    "                       batch_process_function,\n",
    "                       order=6,\n",
    "                       n_workers=8,\n",
    "                       payload=matrix,\n",
    "                       sep_progress=True\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b8f382",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "joblib",
   "language": "python",
   "name": "joblib"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
